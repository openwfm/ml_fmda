{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f4cc18-d23f-48ea-84dc-b0328a65e8e5",
   "metadata": {},
   "source": [
    "# Data Ingest of 10-h Fuel Moisture Content\n",
    "\n",
    "This notebook demonstrates retrieval and filtering of 10-h dead FMC data from RAWS. Retrieval of 10-h FMC observations is done with the software package `SynopticPy` and a stash of RAWS data kept and maintained by the broader OpenWFM community. This notebook will demonstrate use of `Synopticpy` with a free token, so limits are placed on the number of sensor hours that can be requested. Only records within the past year are freely available.\n",
    "\n",
    "The module `ingest/retrieve_raws_api.py` has an executable section and will be run from the command line within this project. Here, the functions are used individually to demonstrate their utility. \n",
    "\n",
    "Time frame and spatial domain for data ingest are controlled in automated processes in the configuration files `training_data_config.json` or the `forecast_config.json` files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c537a5-1963-48ff-a502-30247065a07d",
   "metadata": {},
   "source": [
    "The main steps in the retrieval are:\n",
    "* Use `synoptic.Metadata` to determine the RAWS with FMC data in the given spatial domain and time frame\n",
    "* Use `synoptic.Timeseries` to retrieve all available data that may be relevant to FMC modeling. *NOTE:* the stations are selected so they must have FMC data, and then any other available variables are collected as a bonus. These data are used for exploratory purposes and quality control checks, but predictors for final modeling comes from HRRR.\n",
    "* Format data and convert units.\n",
    "* Identify missing data and interpolate with linear interpolation from numpy\n",
    "\n",
    "The module has a main wrapper function `build_raws_dict` that puts all the steps together. In this module, we will demonstrate the individual steps with the module functions, and then run the main wrapper function at the end and check that it is all the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a0743-ad31-4d16-8307-34cf84b5c28b",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "For more info on python library API, see Brian Blaylock's `SynopticPy` [python package](https://github.com/blaylockbk/SynopticPy)\n",
    "\n",
    "For more info on available Synoptic RAWS variables, see [Synoptic Data](https://demos.synopticdata.com/variables/index.html) documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed774d-7bef-48e7-b9a6-8f4ba4e17d81",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b32fd-9d6b-4582-b724-4d2a094a6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import synoptic\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "sys.path.append('../src')\n",
    "from utils import Dict, read_yml, read_pkl, str2time, rename_dict\n",
    "import ingest.retrieve_raws_api as rfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65b844-5584-4011-b6db-a2a3f0c1fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_meta = read_yml(\"../etc/variable_metadata/raws_metadata.yaml\")\n",
    "\n",
    "with open(\"../etc/training_data_config.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)   \n",
    "    config = Dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91e911-b0dd-4937-b566-c361a2004f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3b261-99c4-4b22-a772-69426284b564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# End result should be the same as this...\n",
    "raws_dict = rfuncs.build_raws_dict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19298030-f0c2-41dd-99ff-530eb6d2eaf8",
   "metadata": {},
   "source": [
    "## Stations MetaData\n",
    "\n",
    "We use `SynopticPy` to get a list of all RAWS stations within the bounding box that have fuel moisture data availability in the given time period.\n",
    "\n",
    "*Note*: the bounding box format used in `wrfxpy` is `[min_lat, min_lon, max_lat, max_lon]`. But, the bounding box format used by Synoptic is `[min_lon, min_lat, max_lon, max_lat]`. The code will assume the `wrfxpy` format and convert internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a20a4-dd0f-44d1-8670-ca914111f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = str2time(config.start_time)\n",
    "end = str2time(config.end_time)\n",
    "bbox = config.bbox\n",
    "bbox_reordered = [bbox[1], bbox[0], bbox[3], bbox[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f6579-4836-463a-b1e6-4ee282d6a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts = rfuncs.get_stations(bbox_reordered)\n",
    "\n",
    "print(sts[\"stid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbefa25-ac25-4164-adbc-187f9740b6b8",
   "metadata": {},
   "source": [
    "## Station Weather Data Time Series\n",
    "\n",
    "Timeseries of observations are drawn for a single RAWS using the `synopticpy` package. Then, the data are formatted by custom funcitons in the `retrieve_raws_api` module. We subtract one hour from the start time because most stations produce data some number of minutes after the requested time, so if you request data at 1:00 the API will return data after that time. Then the temporal interpolation procedure, described below, will be extrapolating out at end points. Shifting the start time by 1 hour accounts for this, but if the start time is longer than 1 year in the past the API will truncate to 1 year. The module has a metadata file with a list of all RAWS weather variables relevant to FMC modeling. \n",
    "\n",
    "The data is returned in \"long\" format, where each weather variable has its own row. We restructure the data into \"wide\" format with the module function `format_raws` so that a single row corresponds to one time, and the columns correspond to different data variables. Additionally, this function converts units and returns a dictionary of all units for the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3adf8-deef-4897-bda5-6376b205efa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_vars = rfuncs.raws_meta[\"raws_weather_vars\"]\n",
    "df_temp = synoptic.TimeSeries(\n",
    "        stid=\"HSYN1\",\n",
    "        start=start-relativedelta(hours=1),\n",
    "        end=end,\n",
    "        vars=weather_vars,\n",
    "        units = \"metric\"\n",
    "    ).df()\n",
    "\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64d531-316c-46a8-8106-b6ffddadfbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, units = rfuncs.format_raws(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ed1f7-4592-46df-b2b8-9c1988444d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a6dc3-cdf3-42c6-ae3e-b58574f5d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a326d07-edf5-4285-a7c0-e81caf1774ed",
   "metadata": {},
   "source": [
    "We then loop over the station IDs found in the previous step and retrieve all available data and then rename and pivot from long to wide. The loop generates a dictionary for each RAWS station with keys for weather data and other metadata.\n",
    "\n",
    "*NOTE*: this process is not parallelized, as the same IP address is used for each request and parallization may result in issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb05f7b-24d7-4811-9b12-d16764d56561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Attempting retrieval of RAWS from {start} to {end} within {bbox}\")\n",
    "print(\"~\"*75)\n",
    "\n",
    "raws_dict = {}\n",
    "\n",
    "for st in sts[\"stid\"]:\n",
    "    print(\"~\"*50)\n",
    "    print(f\"Attempting retrival of station {st}\")\n",
    "    try:\n",
    "        df = synoptic.TimeSeries(\n",
    "            stid=st,\n",
    "            start=start-relativedelta(hours=1),\n",
    "            end=end,\n",
    "            vars=weather_vars,\n",
    "            units = \"metric\"\n",
    "        ).df()\n",
    "    \n",
    "        dat, units = rfuncs.format_raws(df)\n",
    "        loc = rfuncs.get_static(sts, st)\n",
    "        raws_dict[st] = {\n",
    "            'RAWS': dat,\n",
    "            'units': units,\n",
    "            'loc': loc,\n",
    "            'misc': \"Data retrieved using `synoptic.TimeSeries` and formatted with custom functions within `ml_fmda` project.\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc95c3b-bf47-4d85-a3df-919d23a833d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed191a8-78fa-4cfe-92e0-1e005644494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = [*raws_dict.keys()][0]\n",
    "raws_dict[st].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea92b6-4d7a-453d-adf0-46495e761f57",
   "metadata": {},
   "source": [
    "## Fix Time, Interpolate, and Calculate Rain\n",
    "\n",
    "Synoptic may return RAWS data that has missing hours or is returned not exactly on the hour. The missing hours are simply absent in the return data from Synoptic, not marked by NaN. We fix that by filling in NaN for missing hours and interpolating to the exact hour. The resulting data should have regular hourly observations for every RAWS station.\n",
    "\n",
    "Also, this is a good place in the code to rename variables. Various data sources have different variable names, so we standardize with naming conventions from the metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7fb2f-fcab-4322-8308-e5899437b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pl.datetime_range(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    interval=\"1h\",\n",
    "    time_zone = \"UTC\",\n",
    "    eager=True\n",
    ").alias(\"time\")\n",
    "# times = np.array([dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\") for dt in times.to_list()])\n",
    "times = np.array(times.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea61230-cc2b-4f96-b104-23e4bbc87ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = rfuncs.time_intp_df(raws_dict[\"BRLW4\"][\"RAWS\"], times)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106051c-b6ae-45a2-aafe-aaf8445c6de7",
   "metadata": {},
   "source": [
    "We now loop over all stations and run temporal interpolation. We also convert to pandas for easier pickle write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd8c30-2cf0-4d45-9fac-3d0c09d1afb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Interpolating dataframe in time from {times.min()} to {times.max()}\")\n",
    "rename=True\n",
    "if rename:\n",
    "    print(f\"Renaming RAWS columns based on raws_metadata file\")\n",
    "for st in raws_dict:\n",
    "    print(\"~\"*75)\n",
    "    print(st)\n",
    "    nsteps = raws_dict[st][\"RAWS\"].shape[0]\n",
    "    raws_dict[st][\"RAWS\"] = rfuncs.time_intp_df(raws_dict[st][\"RAWS\"], times)\n",
    "    raws_dict[st][\"RAWS\"] = pd.DataFrame(raws_dict[st][\"RAWS\"], columns = raws_dict[st][\"RAWS\"].columns)\n",
    "    raws_dict[st][\"times\"] = times\n",
    "    if raws_dict[st][\"RAWS\"].shape[0] != nsteps:\n",
    "        raws_dict[st][\"misc\"] += \" Interpolated data with numpy linear interpolation.\"\n",
    "        print(f\"    Original Dataframe time steps: {nsteps}\")\n",
    "        print(f\"    Interpolated DataFrame time steps: {raws_dict[st][\"RAWS\"].shape[0]}\")\n",
    "        print(f\"        interpolated {raws_dict[st][\"RAWS\"].shape[0] - nsteps} time steps\")\n",
    "    if rename:\n",
    "        raws_dict[st][\"units\"] = rename_dict(raws_dict[st][\"units\"], raws_meta[\"rename_synoptic\"])\n",
    "        raws_dict[st][\"RAWS\"] = raws_dict[st][\"RAWS\"].rename(columns = raws_meta[\"rename_synoptic\"])\n",
    "        raws_dict[st][\"loc\"] = rename_dict(raws_dict[st][\"loc\"], raws_meta[\"rename_synoptic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7c95f-e7fd-43af-9c64-80625a318310",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict[st][\"units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2457bf-0688-4147-b50d-c1d6c7b83181",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict[\"BRLW4\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac512fe9-6309-45e1-bd85-86225123a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict[\"BRLW4\"][\"RAWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b8dc0-d6ff-407b-b43e-bca4593cc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict[\"BRLW4\"][\"loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c8e49-11a1-47b6-bc67-40173ca0d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict[\"BRLW4\"][\"units\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4291b981-16a3-4af5-9353-ba83e0e5b81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c716a4-4345-46df-a091-9b0894e03b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dbcf75-9317-4a59-b902-d1ae3909d037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c5406-abc1-4fc0-86cc-dc9da8da157a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
