{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f4cc18-d23f-48ea-84dc-b0328a65e8e5",
   "metadata": {},
   "source": [
    "# Build Machine Learning Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed774d-7bef-48e7-b9a6-8f4ba4e17d81",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b32fd-9d6b-4582-b724-4d2a094a6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from datetime import datetime, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import synoptic\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "sys.path.append('../src')\n",
    "from utils import Dict, read_yml, read_pkl, str2time, print_dict_summary, time_range, rename_dict\n",
    "import ingest.retrieve_raws_api as rr\n",
    "import ingest.retrieve_raws_stash as rrs\n",
    "import ingest.retrieve_hrrr_api as ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65b844-5584-4011-b6db-a2a3f0c1fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../etc/training_data_config.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)   \n",
    "    config = Dict(config)\n",
    "print_dict_summary(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffca74-8c6d-45b0-9726-cd2a0687a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_data = read_yml(\"../etc/params_data.yaml\")\n",
    "print_dict_summary(params_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331376db-ab47-46cb-bd9b-04830e574a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_stash_path = rrs.raws_meta[\"raws_stash_path\"]\n",
    "print(raws_stash_path)\n",
    "osp.exists(raws_stash_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05eb21-3b84-4de1-96a9-40ee2826b851",
   "metadata": {},
   "source": [
    "## Retrieve Data\n",
    "\n",
    "Nested dictionary with top level key corresponding to a RAWS and subkeys for RAWS, atmospheric data (HRRR), geographic info, etc\n",
    "\n",
    "This format is used because different FMC models used in this project require different data formatting. The ODE+KF physics-based model is run pointwise and does not incorporate info from other locations. The static ML models have the least restrictive input data structure, and all observations can be thrown into one set of tabular data. The RNN models require structuring input data with the format (batch_size, timesteps, features). Thus, it is simpler to keep all data separate at separate locations and recombine in various ways at the modeling step. Also, data filters for suspect RAWS sensors are applied in the next step. This is because the raw data retrieval should not depend on hyperparameter choices related to data filters, so it is easier to collect everything and apply filters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb577483-4fc2-49f3-99b3-6cd671e5de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict = rrs.build_raws_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab1140-7fa3-4102-93d7-b94451b68d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_dict_summary(raws_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5c1ae-674b-4408-970e-b8d4287aba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_ds = ih.retrieve_hrrr(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c698e-f981-4583-871c-b0db106c517d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hrrr_pts = ih.subset_hrrr2raws(hrrr_ds, raws_dict)\n",
    "hrrr_pts = ih.rename_ds(hrrr_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c773da-d516-4336-9bbe-cb52b53df3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrrr_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b917e-aa2f-4827-b568-b4b14c1e14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check same STIDs\n",
    "np.all(hrrr_pts.point_stid.to_numpy() == np.array([*raws_dict.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400cf95-cd8b-4d99-bb38-3a056da6a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "for st in raws_dict:\n",
    "\n",
    "    # Comfirm times match. For HRRR data it should be the valid_time which accounts for forecast hour\n",
    "    # raws_timesi = np.array([dt.replace(tzinfo=None) for dt in raws_dict[st][\"times\"]], dtype=\"datetime64\")\n",
    "    raws_timesi = raws_dict[st][\"times\"]\n",
    "    assert np.all(raws_timesi == hrrr_pts.valid_time.to_numpy()), \"Times in RAWS dict don't match HRRR data valid_time\"\n",
    "\n",
    "    # Extract dataframe of predictors, save in HRRR subdictionary\n",
    "    df = hrrr_pts.where(hrrr_pts.point_stid == st, drop=True).to_dataframe()\n",
    "    df.reset_index('point', drop=True, inplace=True)\n",
    "    raws_dict[st][\"HRRR\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69d6a6-11cd-4582-bdda-62c11c5190b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict[\"BRLW4\"][\"HRRR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acc047-3527-4a9e-83cd-de58d5e40cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_dict_summary(raws_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91432967-f27d-4c15-9c76-a67e83e009d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a8e8c-697c-4549-bf7a-c64534700c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "osp.join(\"data\", config.training_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9d0ba-3f6b-4a89-a16f-f87d74fca78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11870378-f722-423e-9ab7-82ca9dfdad2e",
   "metadata": {},
   "source": [
    "## Filter Data\n",
    "\n",
    "The file `etc/params_data.yaml` has hyperparameters related to filtering data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176544c-e363-44c9-baf1-732e09067a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437d6d3-6b96-48a0-ade3-6c77f4aa383f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f339e91d-6c3e-4134-ba22-651c4a3ee790",
   "metadata": {},
   "source": [
    "## Setup CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c3f22-57e5-4014-badf-1d58a03c35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to filter dataframe on time\n",
    "def filter_df(df, filter_col, ts):\n",
    "    return df[df[filter_col].isin(ts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7327d-0901-4c1f-81c7-47f70fb405d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import reproducibility\n",
    "import copy\n",
    "\n",
    "def train_test_split_spacetime(d0, start, end, \n",
    "                               space_fracs = [1.0, 0.0, 0.0], \n",
    "                               test_time_steps = 2,\n",
    "                               val_time_steps = 2,\n",
    "                               verbose=False,random_state = 42):\n",
    "    \"\"\"\n",
    "    Train test split, accounting for spatial and temporal dependence\n",
    "    \"\"\"\n",
    "    # Set up \n",
    "    d = copy.deepcopy(d0)\n",
    "    reproducibility.set_seed(random_state)\n",
    "    assert np.sum(space_fracs) == 1., f\"Provided cross validation param space_fracs don't sum to 1\"\n",
    "    if len(space_fracs) != 3:\n",
    "        raise ValueError(\"Cross-validation params `time_fracs` must be list of length 3, representing (train/validation/test)\")\n",
    "\n",
    "    # Temporal setup\n",
    "    times = time_range(start, end)\n",
    "    ntimes = len(times)\n",
    "    train_times = times[0:(ntimes - test_time_steps - val_time_steps)]\n",
    "    val_times = times[(ntimes - test_time_steps - val_time_steps):(ntimes - test_time_steps)]\n",
    "    test_times = times[(ntimes-test_time_steps):]\n",
    "    if verbose:\n",
    "        print(f\"Training period: ({train_times[0]}) to ({train_times[-1]})\")\n",
    "        if len(val_times) >0:\n",
    "            print(f\"Validation period: ({val_times[0]}) to ({val_times[-1]})\")\n",
    "        if len(test_times) >0:\n",
    "            print(f\"Test period: ({test_times[0]}) to ({test_times[-1]})\")\n",
    "    \n",
    "    # Spatial setup\n",
    "    stids = [*d.keys()]\n",
    "    locs = np.arange(len(stids)) # indices of locations\n",
    "    train_size = int(len(locs) * space_fracs[0])\n",
    "    val_size = int(np.ceil(len(locs)*space_fracs[1]))\n",
    "    test_size = len(locs) - train_size - val_size \n",
    "    if verbose:\n",
    "        print(f\"Number of unique locations: {len(stids)}\")\n",
    "        print(f\"Number of training locs: {train_size}\")\n",
    "        print(f\"Number of val locs: {val_size}\")\n",
    "        print(f\"Number of test locs: {test_size}\")\n",
    "    \n",
    "\n",
    "    # Spatial holdout\n",
    "    random.shuffle(stids)\n",
    "    train_locs = stids[:train_size]\n",
    "    val_locs = stids[train_size:(train_size+val_size)]\n",
    "    test_locs = stids[(train_size+val_size):]\n",
    "    train_dict = {k: d[k] for k in train_locs}\n",
    "    val_dict = {k: d[k] for k in val_locs}\n",
    "    test_dict = {k: d[k] for k in test_locs}\n",
    "\n",
    "    # Temporal holdout\n",
    "    for st in train_dict:\n",
    "        train_dict[st][\"times\"] = train_times\n",
    "        train_dict[st][\"RAWS\"] = filter_df(train_dict[st][\"RAWS\"], \"date_time\", train_times)\n",
    "        train_dict[st][\"HRRR\"] = filter_df(train_dict[st][\"HRRR\"], \"valid_time\", train_times)\n",
    "        \n",
    "    for st in val_dict:\n",
    "        val_dict[st][\"times\"] = val_times\n",
    "        val_dict[st][\"RAWS\"] = filter_df(val_dict[st][\"RAWS\"], \"date_time\", val_times)\n",
    "        val_dict[st][\"HRRR\"] = filter_df(val_dict[st][\"HRRR\"], \"valid_time\", val_times)\n",
    "                \n",
    "    for st in test_dict:\n",
    "        test_dict[st][\"times\"] = test_times\n",
    "        test_dict[st][\"RAWS\"] = filter_df(test_dict[st][\"RAWS\"], \"date_time\", test_times)\n",
    "        test_dict[st][\"HRRR\"] = filter_df(test_dict[st][\"HRRR\"], \"valid_time\", test_times)\n",
    "                \n",
    "    \n",
    "    return train_dict, val_dict, test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646ae7e-7b8f-4c12-8979-b39622e9d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = train_test_split_spacetime(raws_dict, config.start_time, config.end_time,\n",
    "                                     space_fracs = [.8, .1, .1],\n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200db90c-24b3-4e85-9de9-d6300a28ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4e098-96d9-4888-91d3-afd0896d3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"WPKS2\"][\"RAWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49522355-36ba-4c11-9d54-ff2111625cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"WPKS2\"][\"HRRR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76087c-94cb-45cb-bd5d-2ff7e3391731",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9fd10-2780-4412-adc3-6887b33dbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"NMOS2\"][\"RAWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7069e4-5ece-424e-9bf3-50ea1b7e10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"NMOS2\"][\"HRRR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add88421-84bc-46ef-99d0-8bbfb9350642",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261e455-25b0-4c01-b75b-3b273d386f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"BRLW4\"][\"RAWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c8e7b-4a1f-4c9f-9438-dafd6ac41663",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"BRLW4\"][\"HRRR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7524eb8-761e-43a7-b1b9-78c8b9479027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c743ffe6-53d3-4388-8c7e-fb58b943ed78",
   "metadata": {},
   "source": [
    "## Run ODE+KF\n",
    "\n",
    "The physics-based ODE+KF model does not require any restructuring of the fmda dictionary built above. \n",
    "\n",
    "Intended use: run directly on stations identified as test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621eda40-8802-469b-afc8-dc285e56ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Dict(read_yml(\"../etc/params_models.yaml\", subkey=\"ode\"))\n",
    "print_dict_summary(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d449133-7a6d-4249-b633-762be89a5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c29ee-78e5-4331-850f-7d19dc38141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE_FMC:\n",
    "    def __init__(self, params):\n",
    "        # List of required keys\n",
    "        required_keys = ['spinup_hours',\n",
    "                         'process_variance',\n",
    "                         'data_variance',\n",
    "                         'r0',\n",
    "                         'rs',\n",
    "                         'Tr',\n",
    "                         'S',\n",
    "                         'T']\n",
    "\n",
    "        # Validate that all required keys are in params\n",
    "        missing_keys = [key for key in required_keys if key not in params]\n",
    "        if missing_keys:\n",
    "            raise ValueError(f\"Missing required keys in params: {missing_keys}\")\n",
    "\n",
    "        # Define params\n",
    "        process_variance = np.float_(params['process_variance'])\n",
    "        self.Q = np.array([[process_variance, 0.],\n",
    "                           [0., process_variance]])\n",
    "        self.H = np.array([[1., 0.]]) # observation matrix\n",
    "        self.R = np.array([np.float_(params['data_variance'])]) # data variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25728369-a85f-4c71-badc-b9ebac97b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ODE_FMC(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24c968-deae-4720-aa79-d4745e36aa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204befe-e076-4c10-a84c-f8864f80208b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9dbe7-513f-4a4e-9442-b34a9247c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = 10\n",
    "P = np.zeros((2,2,hours))\n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990df39a-5120-4793-aa8e-e3b45e3087cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "P[:,:,0] = np.array([[1e-3, 0.],\n",
    "                      [0.,  1e-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8bf73a-a102-4c29-8ea9-2b2c2c3128a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add578c3-d9f8-4956-88a7-9ca61f4e782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56b7eb-54b2-41f0-86ac-fc9ac78db13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750172e7-5994-4d1b-b4bd-d68f9e8a8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.moisture_models\n",
    "importlib.reload(models.moisture_models)\n",
    "import models.moisture_models as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed1fe3a-abc6-44e6-af11-a16230ec2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_kf = {}\n",
    "for st in raws_dict:\n",
    "    print(\"~\"*50)\n",
    "    print(st)\n",
    "    # # Run Augmented KF\n",
    "    # print('Running Augmented KF')\n",
    "    # train[case]['h2'] = test_ind\n",
    "    # train[case]['hours'] =len(train[case]['y'])\n",
    "    # train[case]['scale_fm'] = 1\n",
    "    # m, Ec = run_augmented_kf(train[case])\n",
    "    # y = train[case]['y']        \n",
    "    # train[case]['m_kf'] = m\n",
    "    # print(f\"KF RMSE: {rmse(m[test_ind:],y[test_ind:])}\")\n",
    "    # outputs_kf[case] = {'case':case, 'errs': rmse(m[test_ind:],y[test_ind:])}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b429efc-8d36-4b4c-81ac-2c67764ec5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148bcf9-3799-406f-8ffe-dd2b17e46fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
