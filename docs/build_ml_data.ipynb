{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f4cc18-d23f-48ea-84dc-b0328a65e8e5",
   "metadata": {},
   "source": [
    "# Build Machine Learning Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed774d-7bef-48e7-b9a6-8f4ba4e17d81",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b32fd-9d6b-4582-b724-4d2a094a6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from datetime import datetime, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import synoptic\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "sys.path.append('../src')\n",
    "from utils import Dict, read_yml, read_pkl, str2time, print_dict_summary, time_range, rename_dict\n",
    "import ingest.retrieve_raws_api as rr\n",
    "import ingest.retrieve_raws_stash as rrs\n",
    "import ingest.retrieve_hrrr_api as ih\n",
    "from data_funcs import retrieve_fmda_data, combine_fmda_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65b844-5584-4011-b6db-a2a3f0c1fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../etc/training_data_config.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)   \n",
    "    config = Dict(config)\n",
    "print_dict_summary(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffca74-8c6d-45b0-9726-cd2a0687a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_data = read_yml(\"../etc/params_data.yaml\")\n",
    "print_dict_summary(params_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331376db-ab47-46cb-bd9b-04830e574a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_stash_path = rrs.raws_meta[\"raws_stash_path\"]\n",
    "print(raws_stash_path)\n",
    "osp.exists(raws_stash_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05eb21-3b84-4de1-96a9-40ee2826b851",
   "metadata": {},
   "source": [
    "## Retrieve Data\n",
    "\n",
    "Nested dictionary with top level key corresponding to a RAWS and subkeys for RAWS, atmospheric data (HRRR), geographic info, etc\n",
    "\n",
    "This format is used because different FMC models used in this project require different data formatting. The ODE+KF physics-based model is run pointwise and does not incorporate info from other locations. The static ML models have the least restrictive input data structure, and all observations can be thrown into one set of tabular data. The RNN models require structuring input data with the format (batch_size, timesteps, features). Thus, it is simpler to keep all data separate at separate locations and recombine in various ways at the modeling step. Also, data filters for suspect RAWS sensors are applied in the next step. This is because the raw data retrieval should not depend on hyperparameter choices related to data filters, so it is easier to collect everything and apply filters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0fa73-ad02-4fde-818e-9163b5049605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# config.update({\"end_time\": \"2023-06-03T23:00:00Z\"})\n",
    "# dat = retrieve_fmda_data(config, save_filename=\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7884f-e51b-499f-be83-8019e7200fb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# config.update({\n",
    "#     \"start_time\" : \"2023-08-01T00:00:00Z\",\n",
    "#     \"end_time\" : \"2023-08-01T04:00:00Z\",\n",
    "#     \"bbox\": [38, -107, 47, -98]\n",
    "# })\n",
    "\n",
    "# dat = retrieve_fmda_data(config, save_filename=\"test2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0547a5-0e20-4deb-a42b-524d78315726",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"../data/test.pkl\", \"../data/test2.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b41eb6-099b-453a-9afa-8547ddd5966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raws_dict = combine_fmda_files(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11870378-f722-423e-9ab7-82ca9dfdad2e",
   "metadata": {},
   "source": [
    "## Filter Data\n",
    "\n",
    "The file `etc/params_data.yaml` has hyperparameters related to filtering data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b176544c-e363-44c9-baf1-732e09067a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437d6d3-6b96-48a0-ade3-6c77f4aa383f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f339e91d-6c3e-4134-ba22-651c4a3ee790",
   "metadata": {},
   "source": [
    "## Setup CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c3f22-57e5-4014-badf-1d58a03c35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to filter dataframe on time\n",
    "def filter_df(df, filter_col, ts):\n",
    "    return df[df[filter_col].isin(ts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa7327d-0901-4c1f-81c7-47f70fb405d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import reproducibility\n",
    "import copy\n",
    "\n",
    "def train_test_split_spacetime(d0, start, end, \n",
    "                               space_fracs = [1.0, 0.0, 0.0], \n",
    "                               test_time_steps = 2,\n",
    "                               val_time_steps = 2,\n",
    "                               verbose=False,random_state = 42):\n",
    "    \"\"\"\n",
    "    Train test split, accounting for spatial and temporal dependence\n",
    "    \"\"\"\n",
    "    # Set up \n",
    "    d = copy.deepcopy(d0)\n",
    "    reproducibility.set_seed(random_state)\n",
    "    assert np.sum(space_fracs) == 1., f\"Provided cross validation param space_fracs don't sum to 1\"\n",
    "    if len(space_fracs) != 3:\n",
    "        raise ValueError(\"Cross-validation params `time_fracs` must be list of length 3, representing (train/validation/test)\")\n",
    "\n",
    "    # Temporal setup\n",
    "    times = time_range(start, end)\n",
    "    ntimes = len(times)\n",
    "    train_times = times[0:(ntimes - test_time_steps - val_time_steps)]\n",
    "    val_times = times[(ntimes - test_time_steps - val_time_steps):(ntimes - test_time_steps)]\n",
    "    test_times = times[(ntimes-test_time_steps):]\n",
    "    if verbose:\n",
    "        print(f\"Training period: ({train_times[0]}) to ({train_times[-1]})\")\n",
    "        if len(val_times) >0:\n",
    "            print(f\"Validation period: ({val_times[0]}) to ({val_times[-1]})\")\n",
    "        if len(test_times) >0:\n",
    "            print(f\"Test period: ({test_times[0]}) to ({test_times[-1]})\")\n",
    "    \n",
    "    # Spatial setup\n",
    "    stids = [*d.keys()]\n",
    "    locs = np.arange(len(stids)) # indices of locations\n",
    "    train_size = int(len(locs) * space_fracs[0])\n",
    "    val_size = int(np.ceil(len(locs)*space_fracs[1]))\n",
    "    test_size = len(locs) - train_size - val_size \n",
    "    if verbose:\n",
    "        print(f\"Number of unique locations: {len(stids)}\")\n",
    "        print(f\"Number of training locs: {train_size}\")\n",
    "        print(f\"Number of val locs: {val_size}\")\n",
    "        print(f\"Number of test locs: {test_size}\")\n",
    "    \n",
    "\n",
    "    # Spatial holdout\n",
    "    random.shuffle(stids)\n",
    "    train_locs = stids[:train_size]\n",
    "    val_locs = stids[train_size:(train_size+val_size)]\n",
    "    test_locs = stids[(train_size+val_size):]\n",
    "    train_dict = {k: d[k] for k in train_locs}\n",
    "    val_dict = {k: d[k] for k in val_locs}\n",
    "    test_dict = {k: d[k] for k in test_locs}\n",
    "\n",
    "    # Temporal holdout\n",
    "    for st in train_dict:\n",
    "        train_dict[st][\"times\"] = train_times\n",
    "        train_dict[st][\"RAWS\"] = filter_df(train_dict[st][\"RAWS\"], \"date_time\", train_times)\n",
    "        train_dict[st][\"HRRR\"] = filter_df(train_dict[st][\"HRRR\"], \"valid_time\", train_times)\n",
    "        \n",
    "    for st in val_dict:\n",
    "        val_dict[st][\"times\"] = val_times\n",
    "        val_dict[st][\"RAWS\"] = filter_df(val_dict[st][\"RAWS\"], \"date_time\", val_times)\n",
    "        val_dict[st][\"HRRR\"] = filter_df(val_dict[st][\"HRRR\"], \"valid_time\", val_times)\n",
    "                \n",
    "    for st in test_dict:\n",
    "        test_dict[st][\"times\"] = test_times\n",
    "        test_dict[st][\"RAWS\"] = filter_df(test_dict[st][\"RAWS\"], \"date_time\", test_times)\n",
    "        test_dict[st][\"HRRR\"] = filter_df(test_dict[st][\"HRRR\"], \"valid_time\", test_times)\n",
    "                \n",
    "    \n",
    "    return train_dict, val_dict, test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646ae7e-7b8f-4c12-8979-b39622e9d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = train_test_split_spacetime(raws_dict, config.start_time, config.end_time,\n",
    "                                     space_fracs = [.8, .1, .1],\n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200db90c-24b3-4e85-9de9-d6300a28ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4e098-96d9-4888-91d3-afd0896d3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"WPKS2\"][\"RAWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49522355-36ba-4c11-9d54-ff2111625cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"WPKS2\"][\"HRRR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76087c-94cb-45cb-bd5d-2ff7e3391731",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9fd10-2780-4412-adc3-6887b33dbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "val[\"TS897\"][\"RAWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7069e4-5ece-424e-9bf3-50ea1b7e10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val[\"TS897\"][\"HRRR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add88421-84bc-46ef-99d0-8bbfb9350642",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261e455-25b0-4c01-b75b-3b273d386f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"SAWW4\"][\"RAWS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c8e7b-4a1f-4c9f-9438-dafd6ac41663",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"SAWW4\"][\"HRRR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7524eb8-761e-43a7-b1b9-78c8b9479027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c743ffe6-53d3-4388-8c7e-fb58b943ed78",
   "metadata": {},
   "source": [
    "## Run ODE+KF\n",
    "\n",
    "The physics-based ODE+KF model does not require any restructuring of the fmda dictionary built above. \n",
    "\n",
    "Intended use: run directly on stations identified as test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cb526-2021-44f3-9672-593c1deac79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.moisture_models\n",
    "importlib.reload(models.moisture_models)\n",
    "import models.moisture_models as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12473d1c-682c-44c2-85cd-7eae7fbf7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ode = mm.ODE_FMC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d5c8c-74a2-43ef-b69e-bc066f2263b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, errs = ode.run_model(raws_dict, hours=6, h2=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f68348c-a5fc-423c-bf9d-e7140b82e09b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c41712f-a4f6-4236-a161-820acf0aac90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621eda40-8802-469b-afc8-dc285e56ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Dict(read_yml(\"../etc/params_models.yaml\", subkey=\"ode\"))\n",
    "print_dict_summary(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d449133-7a6d-4249-b633-762be89a5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c29ee-78e5-4331-850f-7d19dc38141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODE_FMC:\n",
    "    def __init__(self, params):\n",
    "        # List of required keys\n",
    "        required_keys = ['spinup_hours',\n",
    "                         'process_variance',\n",
    "                         'data_variance',\n",
    "                         'r0',\n",
    "                         'rs',\n",
    "                         'Tr',\n",
    "                         'S',\n",
    "                         'T']\n",
    "\n",
    "        # Validate that all required keys are in params\n",
    "        missing_keys = [key for key in required_keys if key not in params]\n",
    "        if missing_keys:\n",
    "            raise ValueError(f\"Missing required keys in params: {missing_keys}\")\n",
    "\n",
    "        # Define params\n",
    "        self.params = params\n",
    "        process_variance = np.float_(params['process_variance'])\n",
    "        self.Q = np.array([[process_variance, 0.],\n",
    "                           [0., process_variance]])\n",
    "        self.H = np.array([[1., 0.]]) # observation matrix\n",
    "        self.R = np.array([np.float_(params['data_variance'])]) # data variance\n",
    "        self.r0 = params[\"r0\"]\n",
    "        self.rs = params[\"rs\"]\n",
    "        self.Tr = params[\"Tr\"]\n",
    "        self.S = params[\"S\"]\n",
    "        self.T = params[\"T\"]\n",
    "    def run_model_single(self, dat, hours, h2, atm_source = \"HRRR\"):\n",
    "        \"\"\"\n",
    "        Run ODE fuel moisture model on a single location. \n",
    "        \n",
    "        hours : int\n",
    "            Total hours to run model\n",
    "\n",
    "        h2 : int\n",
    "            Hour to turn off data assimilation and run in forecast mode\n",
    "        \n",
    "        atm_source: str\n",
    "            Typically HRRR. Should be able to do RAWS as QC\n",
    "        \"\"\"\n",
    "        Q = self.Q\n",
    "        R = self.R\n",
    "        H = self.H\n",
    "        \n",
    "        fm = dat[\"RAWS\"][\"fm\"].to_numpy().astype(np.float64)\n",
    "        Ed = dat[atm_source][\"Ed\"].to_numpy().astype(np.float64)\n",
    "        Ew = dat[atm_source][\"Ew\"].to_numpy().astype(np.float64)\n",
    "        rain = dat[atm_source][\"rain\"].to_numpy().astype(np.float64)\n",
    "\n",
    "        u = np.zeros((2,hours))\n",
    "        u[:,0]=[0.1,0.0]       # initialize,background state  \n",
    "        P = np.zeros((2,2,hours))\n",
    "        P[:,:,0] = np.array([[self.params['process_variance'], 0.],\n",
    "                      [0.,  self.params['process_variance']]]) # background state covariance        \n",
    "        \n",
    "        # Run in spinup mode\n",
    "        for t in range(1,h2):\n",
    "          # use lambda construction to pass additional arguments to the model \n",
    "            u[:,t],P[:,:,t] = mm.ext_kf(u[:,t-1],P[:,:,t-1],\n",
    "                                    lambda uu: mm.model_augmented(uu,Ed[t],Ew[t],rain[t],t),\n",
    "                                    Q,d=fm[t],H=H,R=R)\n",
    "\n",
    "        # Run in forecast mode\n",
    "        for t in range(h2,hours):\n",
    "            u[:,t],P[:,:,t] = mm.ext_kf(u[:,t-1],P[:,:,t-1],\n",
    "                                      lambda uu: mm.model_augmented(uu,Ed[t],Ew[t],rain[t],t),\n",
    "                                      Q*0.0)\n",
    "          \n",
    "        return u\n",
    "\n",
    "    def run_dict(self, dict0, hours, h2, atm_source=\"HRRR\"):\n",
    "        \"\"\"\n",
    "        Run model defined in run_model_single on a dictionary and return 3d array\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        u : ndarray\n",
    "            state vector 3d array of dims (n_locations, timesteps, 2), where 2 dim response is FMC, Ec\n",
    "        \"\"\"\n",
    "        u = []\n",
    "        for st in dict0:\n",
    "            ui = self.run_model_single(dict0[st], hours=hours, h2=h2, atm_source=atm_source)\n",
    "            u.append(ui.T) # transpose to get dimesion (timesteps, response_dim)\n",
    "\n",
    "        u = np.stack(u, axis=0)\n",
    "        \n",
    "        return u\n",
    "\n",
    "    def slice_fm_forecasts(self, u, h2):\n",
    "        \"\"\"\n",
    "        Given output of run_model, slice array to get only FMC at forecast hours\n",
    "        \"\"\"\n",
    "\n",
    "        return u[:, h2:, 0:1] # Using 0:1 keeps the dimensions, if just 0 it will drop\n",
    "    \n",
    "    def eval(self, u, fm, h2):\n",
    "        \"\"\"\n",
    "        Return RMSE of forecast u versus observed FMC\n",
    "        \"\"\"\n",
    "        assert u.shape == fm.shape, \"Arrays must have the same shape.\"\n",
    "        # Reshape to 2D: (N * timesteps, features)\n",
    "        fm2 = x.reshape(-1, x.shape[-1])\n",
    "        u2 = u.reshape(-1, u.shape[-1])\n",
    "        rmse = np.sqrt(mean_squared_error(u2, fm2))\n",
    "    \n",
    "        return rmse\n",
    "\n",
    "    def run_model(self, dict0, hours, h2, atm_source=\"HRRR\"):\n",
    "        \"\"\"\n",
    "        Put it all together\n",
    "        \"\"\"\n",
    "\n",
    "        # Get array of response\n",
    "        fm_arrays = [raws_dict[loc][\"RAWS\"][\"fm\"].values[h2:, np.newaxis] for loc in raws_dict]\n",
    "        fm = np.stack(fm_arrays, axis=0)\n",
    "\n",
    "        # Get forecasts\n",
    "        preds = self.run_dict(dict0, hours=hours, h2=h2, atm_source=atm_source)\n",
    "        m = self.slice_fm_forecasts(preds, h2 = h2)\n",
    "\n",
    "        rmse = self.eval(m, fm, h2)\n",
    "\n",
    "        return m, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25728369-a85f-4c71-badc-b9ebac97b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ODE_FMC(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3449dc-1438-405b-868c-dd55c1c7c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.moisture_models as mm\n",
    "d = raws_dict[\"BRLW4\"]\n",
    "m, Ec = mod.run_model_single(d, hours = 6, h2 = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24c968-deae-4720-aa79-d4745e36aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e9145f-bb4d-46b0-bf49-f29df4b34387",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9cb09d-cfb2-4c4b-87bc-242f4b68dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "us = mod.run_dict(raws_dict, hours=6, h2=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7d86b-5917-4912-8a51-7d8c739e7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = mod.slice_fm_forecasts(us, h2 = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204befe-e076-4c10-a84c-f8864f80208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = 2\n",
    "fm_arrays = [raws_dict[loc][\"RAWS\"][\"fm\"].values[h2:, np.newaxis] for loc in raws_dict]\n",
    "x = np.stack(fm_arrays, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88311177-7377-4deb-8d63-97b993f92cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c9ca3-a160-4dc9-8b58-b0e789c87b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da92bf-9004-4990-a304-696005c3e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041154a-091c-4692-8cfd-7f8e0053f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, errs = mod.run_model(raws_dict, hours=6, h2=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68b533-0ce4-4afc-a62f-ac148900b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42bfea-437c-4e0c-864f-480e41cacba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148bcf9-3799-406f-8ffe-dd2b17e46fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
