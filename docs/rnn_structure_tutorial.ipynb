{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f4cc18-d23f-48ea-84dc-b0328a65e8e5",
   "metadata": {},
   "source": [
    "# Build Machine Learning Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79db2ac-aa72-4e5f-85e0-e21def49917d",
   "metadata": {},
   "source": [
    "This notebook is meant to describe aspects of RNN model architectures.  \n",
    "\n",
    "In this project, we use the Functional API to tensorflow for 2 reasons:\n",
    "1. It allows for dynamic hidden layer building. With the Functional API, we loop over a list of hidden layers and add an arbitrary number of layers. The Sequential API does not make this easy\n",
    "2. When visualizing models with `model.summary()`, the Functional API treats the input as a layer and will show the input shape, while Sequential does not and thus makes the summary less informative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed774d-7bef-48e7-b9a6-8f4ba4e17d81",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b32fd-9d6b-4582-b724-4d2a094a6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import reproducibility\n",
    "from utils import read_pkl, hash_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dda0d6-eeba-49d1-99a8-168f83afa927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = read_pkl(\"../data/test_data/test_rnn_dat.pkl\")\n",
    "# dat.scale_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3413a-9eb9-4444-a14c-10ac9009e41b",
   "metadata": {},
   "source": [
    "## Input Shape\n",
    "\n",
    "### Overview\n",
    "\n",
    "All RNN layers have an input shape of `(batch_size, timesteps, features)`. This applies to SimpleRNN layers as well as LSTM and GRU. (Does NOT apply to attention layers and transformers). These shape hyperparameters control how data is fed into the network\n",
    "\n",
    "* `batch_size`: the number of samples in a batch (aka minibatch) of training. After all samples in a batch are passed through the network *independently*, the loss is calculated and model weights are updated\n",
    "* `timesteps`: the number of timesteps that defines a single sample input. Also referred to as \"sequence length\"\n",
    "* `features`: the dimesionality of predictors/covariates/independent variables\n",
    "\n",
    "So in a given batch, samples of shape `(timesteps, features)` are passed through the network. Each sample is processed by each recurrent cell (e.g. a LSTM cell). In tensorflow, the `Input()` layer is used to control the input shape. \n",
    "\n",
    "See [Keras documentation](https://keras.io/api/layers/core_layers/input/) for more details\n",
    "\n",
    "### Flexible vs Fixed Input Shapes\n",
    "\n",
    "The `batch_size` and the `timesteps` hyperparameters can either be fixed to an integer value, or be set to `None`. There are two programmatically equivalent ways to set `batch_size` to `None` in tensorflow:\n",
    "\n",
    "* `Input(shape=(timesteps, features))`: implicitely sets `batch_size` to `None`\n",
    "* `Input(batch_shape=(None, timesteps, features))`: explicitely sets `batch_size` to `None`\n",
    "\n",
    "Further, there is the option to set the batch_size at the time of calling fit: `model.fit(batch_size=___)`. While it seems like this should be redundant, tensorflow has a way of dynamically adjusting things where if you don't explicitly set batch_size and give input data of different shapes, it will try to reconcile and make things work leading to unexpected results.\n",
    "\n",
    "If these hyperparameters are set to None, there are different consequences.\n",
    "\n",
    "* `batch_size`: If set to `None`, the network can accept input data with any positive integer number of batches.\n",
    "    * The model still needs a batch size to process training gradient descent, and tensorflow will default to a `batch_size` of 32 unless otherwise directed. In tensorflow, `batch_size` is set in the `.fit(batch_size = __)` method if it was set to None initially\n",
    "    * This *will NOT* work with a `stateful` model, which requires consistent batch sizes because it needs to know how to pass hidden states\n",
    "\n",
    "* `timesteps`: If set to `None`, the network can accept input data with any positive integer number of timesteps\n",
    "\n",
    "    * In practice it will be determined by the input array that is passed to the `.fit` or `.predict` call\n",
    "\n",
    "\n",
    "In this project, we fix `batch_size` and `timesteps` during training since it allows for a more systematic hyperparameter tuning procedure. In other words, you can test various values of these hyperparameters and evaluate which leads to the most accurate models. However, when predicting with a trained model, we want to be able to forecast values at an arbitrary number of locations and arbitrarily far into the future. So for forecasting, we want these hyperparmeters to be `None`. Fortunately, these hyperparameters do not actually change the number of connections or weights within the network, so we can train a \"training model\" with the fixed hyperparameters, and then copy the weights over to a network with the same number of trainable parameters but with a more flexible input shape, the so-called \"prediction model\". \n",
    "\n",
    "Below we demonstrate the various input shapes and how they data can or cannot be passed through the network. We print a unique hash value of the model weights for each one to demonstrate that the weights of these networks are identical on initialization and following training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82252850-b215-4eb8-9590-7203c959399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to use below\n",
    "features = 3\n",
    "timesteps = 5\n",
    "batch_size = 4\n",
    "\n",
    "# Random Data of various shapes to illustrate compatibility\n",
    "# Assume response variable is 1-d \n",
    "\n",
    "rand1 = np.random.randn(batch_size, timesteps, features)\n",
    "yrand1 = np.random.randn(batch_size, timesteps, 1)\n",
    "\n",
    "rand2 = np.random.randn(batch_size+5, timesteps, features)\n",
    "yrand2 = np.random.randn(batch_size+5, timesteps, 1)\n",
    "\n",
    "rand3 = np.random.randn(batch_size+5, timesteps+5, features)\n",
    "yrand3 = np.random.randn(batch_size+5, timesteps+5, 1)\n",
    "\n",
    "print(rand1.shape)\n",
    "print(rand2.shape)\n",
    "print(rand3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6301282-c872-4652-a834-207c7c4062aa",
   "metadata": {},
   "source": [
    "### Example: Stateful\n",
    "\n",
    "Forces consistent batch size, will not process partial batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dfa01-4436-41c5-9e85-9385b3b6c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(4, stateful=True)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model1 = tf.keras.Model(inputs, outputs, name = \"Stateful\")\n",
    "model1.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70549a-f43e-4698-9251-da0a13daf74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(x=rand1, y = yrand1)\n",
    "print(f\"Trained model weights: {hash_weights(model1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b138ad-3bc8-4c0b-b08e-a2cd612065dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model1.fit(x=rand2, y = yrand2)\n",
    "except Exception as e:\n",
    "    print(\"Error due to incompatible shapes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a8953-f695-415c-8b23-c492d7f8d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model1.fit(x=rand3, y = yrand3)\n",
    "except Exception as e:\n",
    "    print(\"Error due to incompatible shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3bb57-6614-41ad-aa0e-c0ee51ce89b3",
   "metadata": {},
   "source": [
    "### Example: Fixed Batch and Fixed Timesteps\n",
    "\n",
    "Stateful set to default of `False`. The trained model is the same for the stateful model with the same data, but in this case the model can accept incomplete batches and process them without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed1004-f11d-4160-bd7f-c3cbd9adf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model1 = tf.keras.Model(inputs, outputs, name = \"Fixed_Batch-Fixed_Timesteps\")\n",
    "model1.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250af75a-168e-45a0-8e27-c505c4ca1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(x=rand1, y = yrand1, batch_size = batch_size)\n",
    "print(f\"Trained model weights: {hash_weights(model1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d62b0-de0e-4d3a-9102-e055556b77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b12e0-6822-4128-ae92-5e0f9529fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model1 = tf.keras.Model(inputs, outputs, name = \"Fixed_Batch-Fixed_Timesteps\")\n",
    "model1.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "\n",
    "model1.fit(x=rand2, y = yrand2, batch_size=batch_size)\n",
    "\n",
    "print(f\"Trained model weights: {hash_weights(model1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e06fc-b8f8-4b7d-8e99-4059e12d3495",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430303d0-e61d-4a92-9d28-53904657cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: data below throws error when FIRST call to fit, but not\n",
    "# # if model has been fit with proper data already. TODO: Dig into this \n",
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model1 = tf.keras.Model(inputs, outputs, name = \"Fixed_Batch-Fixed_Timesteps\")\n",
    "model1.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "try:\n",
    "    model1.fit(x=rand3, y = yrand3)\n",
    "except Exception as e:\n",
    "    print(\"Error due to incompatible shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740bb6c-ac0e-4208-9fe5-9abdc4dce526",
   "metadata": {},
   "source": [
    "### Example: Flexible Batch, Fixed Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ff784-218a-4fd9-93c5-a9fa65eedb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model2 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Fixed_Timesteps\")\n",
    "model2.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model2)}\")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036df07b-0acd-4f64-b8a1-90ad1789ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x=rand1, y = yrand1)\n",
    "\n",
    "print(f\"Trained model weights: {hash_weights(model2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3277bc5-8aa6-4bd6-8a1c-9b5fbcc6d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model2 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Fixed_Timesteps\")\n",
    "model2.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model2)}\")\n",
    "\n",
    "model2.fit(x=rand2, y = yrand2, batch_size = None)\n",
    "\n",
    "print(f\"Trained model weights: {hash_weights(model2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da454752-dc9d-4123-9af0-246e355b5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model2 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Fixed_Timesteps\")\n",
    "model2.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model2)}\")\n",
    "\n",
    "model2.fit(x=rand2, y = yrand2, batch_size = rand2.shape[0])\n",
    "\n",
    "print(f\"Trained model weights: {hash_weights(model2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87200c-4c18-48da-9e89-548fc84a2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: data below throws error when FIRST call to fit, but not\n",
    "# # if model has been fit with proper data already. TODO: Dig into this \n",
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model2 = tf.keras.Model(inputs, outputs, name = \"Fixed_Batch-Fixed_Timesteps\")\n",
    "model2.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "try:\n",
    "    model2.fit(x=rand3, y = yrand3)\n",
    "except Exception as e:\n",
    "    print(\"Error due to incompatible shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532582f-3baf-4c68-89a3-9c17f32b947a",
   "metadata": {},
   "source": [
    "### Example 3: Flexible Batch Size, Flexible Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23cd927-1945-43cb-8ba1-02707071e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, None, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model3 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Flexible_Timesteps\")\n",
    "model3.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model3)}\")\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7c03e-45a9-41fa-9fb9-e427feacc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(x=rand1, y = yrand1)\n",
    "\n",
    "print(f\"Trained model weights: {hash_weights(model2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a947b-bff6-4041-9949-f2899f045f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, None, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model3 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Flexible_Timesteps\")\n",
    "model3.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model3)}\")\n",
    "\n",
    "model3.fit(x=rand2, y = yrand2, batch_size=None)\n",
    "\n",
    "print(f\"Trained model weights: {hash_weights(model3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0aa10-080f-4805-8b4b-0f77b68fd157",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, None, features))\n",
    "x = tf.keras.layers.SimpleRNN(2)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model3 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Flexible_Timesteps\")\n",
    "model3.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model3)}\")\n",
    "\n",
    "model3.fit(x=rand3, y = yrand3, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e204b8ce-c696-4f97-a4cb-21da029096cd",
   "metadata": {},
   "source": [
    "## Return Sequences\n",
    "\n",
    "All recurrent layers expect an input shape of `(batch_size, timesteps, features)`.  The output shape of the recurrent layer depends on the number of cells, or units, but also the `return_sequences` parameter. \n",
    "* If `return_sequences=True`, each recurrent cell will return a sequence of length `timesteps`\n",
    "* If `return_sequences=False`, each recurrent cell will return only the last value in the sequences, so the max time step in `timesteps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ed981-6a85-4395-bbf0-0c607bcb7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine Hyperparameters for clarity\n",
    "features = 3\n",
    "timesteps = 5\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5f0c6-6db4-44e6-a179-5ebcb5799506",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2, return_sequences=True)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model1 = tf.keras.Model(inputs, outputs, name = \"Return_Sequences_True\")\n",
    "model1.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72acd8-a33e-4a6d-9972-4f96ffabbbe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.SimpleRNN(2, return_sequences=False)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model2 = tf.keras.Model(inputs, outputs, name = \"Return_Sequences_False\")\n",
    "model2.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386973c-0876-48ed-b947-e410d9a74f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277222a0-11b9-4af1-9d63-db9d33777a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "yrand1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591edd8-4b81-4c63-9e6b-aa4708ab0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "model1.fit(rand1, yrand1)\n",
    "print(f\"Trained Model Weights: {hash_weights(model1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7d601-cb99-45f5-8310-a61d4bce6d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "model2.fit(rand1, yrand1)\n",
    "print(f\"Trained Model Weights: {hash_weights(model2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e8e80-55b8-4b8a-8830-5276f53d7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82307b-d24a-4a1a-a33d-31bbd691f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = model1.predict(rand1)\n",
    "preds2 = model2.predict(rand1)\n",
    "print(f\"{preds1.shape=}\")\n",
    "print(f\"{preds2.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f8d7b-f489-44c6-a561-7d2baac572c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861be5ed-73cd-446c-ace9-8c788ee01f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = model1.predict(rand2)\n",
    "preds2 = model2.predict(rand2)\n",
    "print(f\"{preds1.shape=}\")\n",
    "print(f\"{preds2.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944ff62-20b5-42c2-aeda-22f669196113",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e11b8a-1fdd-41f8-bea2-89e50e1bf0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = model1.predict(rand3)\n",
    "preds2 = model2.predict(rand3)\n",
    "print(f\"{preds1.shape=}\")\n",
    "print(f\"{preds2.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0afc0-9cc0-4f86-82df-cf8ad354af6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148163f-108f-4a60-b6d9-6dc473e48205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1024d5-d556-496d-8174-a970db58c2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdcc367-05ed-4056-866f-f56b6e17295d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ced34-d94c-4703-b0fe-f305daae69bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
