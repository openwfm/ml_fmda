{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f4cc18-d23f-48ea-84dc-b0328a65e8e5",
   "metadata": {},
   "source": [
    "# Build Machine Learning Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79db2ac-aa72-4e5f-85e0-e21def49917d",
   "metadata": {},
   "source": [
    "This notebook is meant to describe aspects of RNN model architectures.  \n",
    "\n",
    "In this project, we use the Functional API to tensorflow for 2 reasons:\n",
    "1. It allows for dynamic hidden layer building. With the Functional API, we loop over a list of hidden layers and add an arbitrary number of layers. The Sequential API does not make this easy\n",
    "2. When visualizing models with `model.summary()`, the Functional API treats the input as a layer and will show the input shape, while Sequential does not and thus makes the summary less informative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed774d-7bef-48e7-b9a6-8f4ba4e17d81",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b32fd-9d6b-4582-b724-4d2a094a6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import reproducibility\n",
    "from utils import read_pkl, hash_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dda0d6-eeba-49d1-99a8-168f83afa927",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read_pkl(\"../data/test_data/test_rnn_dat.pkl\")\n",
    "dat.scale_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3413a-9eb9-4444-a14c-10ac9009e41b",
   "metadata": {},
   "source": [
    "## Input Shape\n",
    "\n",
    "### Overview\n",
    "\n",
    "All RNN layers have an input shape of `(batch_size, timesteps, features)`. This applies to SimpleRNN layers as well as LSTM and GRU. (Does NOT apply to attention layers and transformers). These shape hyperparameters control how data is fed into the network\n",
    "\n",
    "* `batch_size`: the number of samples in a batch (aka minibatch) of training. After all samples in a batch are passed through the network *independently*, the loss is calculated and model weights are updated\n",
    "* `timesteps`: the number of timesteps that defines a single sample input. Also referred to as \"sequence length\"\n",
    "* `features`: the dimesionality of predictors/covariates/independent variables\n",
    "\n",
    "So in a given batch, samples of shape `(timesteps, features)` are passed through the network. Each sample is processed by each recurrent cell (e.g. a LSTM cell). In tensorflow, the `Input()` layer is used to control the input shape. \n",
    "\n",
    "See [Keras documentation](https://keras.io/api/layers/core_layers/input/) for more details\n",
    "\n",
    "### Flexible vs Fixed Input Shapes\n",
    "\n",
    "The `batch_size` and the `timesteps` hyperparameters can either be fixed to an integer value, or be set to `None`. There are two programmatically equivalent ways to set `batch_size` to `None` in tensorflow:\n",
    "\n",
    "* `Input(shape=(timesteps, features))`: implicitely sets `batch_size` to `None`\n",
    "* `Input(batch_shape=(None, timesteps, features))`: explicitely sets `batch_size` to `None`\n",
    "\n",
    "If these hyperparameters are set to None, there are different consequences.\n",
    "\n",
    "* `batch_size`: If set to `None`, the network can accept input data with any positive integer number of batches.\n",
    "    * The model still needs a batch size to process training gradient descent, and tensorflow will default to a `batch_size` of 32 unless otherwise directed. In tensorflow, `batch_size` is set in the `.fit(batch_size = __)` method if it was set to None initially\n",
    "    * This *will NOT* work with a `stateful` model, which requires consistent batch sizes because it needs to know how to pass hidden states\n",
    "\n",
    "* `timesteps`: If set to `None`, the network can accept input data with any positive integer number of timesteps\n",
    "\n",
    "    * In practice it will be determined by the input array that is passed to the `.fit` or `.predict` call\n",
    "\n",
    "\n",
    "In this project, we fix `batch_size` and `timesteps` during training since it allows for a more systematic hyperparameter tuning procedure. In other words, you can test various values of these hyperparameters and evaluate which leads to the most accurate models. However, when predicting with a trained model, we want to be able to forecast values at an arbitrary number of locations and arbitrarily far into the future. So for forecasting, we want these hyperparmeters to be `None`. Fortunately, these hyperparameters do not actually change the number of connections or weights within the network, so we can train a \"training model\" with the fixed hyperparameters, and then copy the weights over to a network with the same number of trainable parameters but with a more flexible input shape, the so-called \"prediction model\". \n",
    "\n",
    "Below we demonstrate the various input shapes and how they data can or cannot be passed through the network. We print a unique hash value of the model weights for each one to demonstrate that the weights of these networks are identical on initialization and following training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82252850-b215-4eb8-9590-7203c959399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to use below\n",
    "features = 3\n",
    "timesteps = 12\n",
    "batch_size = 10\n",
    "\n",
    "# Random Data of various shapes to illustrate compatibility\n",
    "# Assume response variable is 1-d \n",
    "\n",
    "rand1 = np.random.randn(batch_size, timesteps, features)\n",
    "yrand1 = np.random.randn(batch_size, timesteps, 1)\n",
    "\n",
    "rand2 = np.random.randn(batch_size+5, timesteps, features)\n",
    "yrand2 = np.random.randn(batch_size+5, timesteps, 1)\n",
    "\n",
    "rand3 = np.random.randn(batch_size+5, timesteps+5, features)\n",
    "yrand3 = np.random.randn(batch_size+5, timesteps+5, 1)\n",
    "\n",
    "print(rand1.shape)\n",
    "print(rand2.shape)\n",
    "print(rand3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6301282-c872-4652-a834-207c7c4062aa",
   "metadata": {},
   "source": [
    "### Example: Stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dfa01-4436-41c5-9e85-9385b3b6c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.LSTM(4, stateful=True)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model1 = tf.keras.Model(inputs, outputs, name = \"Stateful\")\n",
    "model1.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48bded-6a4c-46af-86e7-e5e709327a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(x=rand2, y = yrand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b138ad-3bc8-4c0b-b08e-a2cd612065dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model1.fit(x=rand2, y = yrand2)\n",
    "except Exception as e:\n",
    "    print(\"Error due to incompatible shapes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f3bb57-6614-41ad-aa0e-c0ee51ce89b3",
   "metadata": {},
   "source": [
    "### Example: Fixed Batch and Fixed Timesteps\n",
    "\n",
    "Fixed batch size is *required* for stateful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ed1004-f11d-4160-bd7f-c3cbd9adf645",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(batch_size, timesteps, features))\n",
    "x = tf.keras.layers.LSTM(4)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model1 = tf.keras.Model(inputs, outputs, name = \"Fixed_Batch-Fixed_Timesteps\")\n",
    "model1.compile(loss = \"mean_squared_error\", optimizer=\"Adam\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model1)}\")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b12e0-6822-4128-ae92-5e0f9529fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250af75a-168e-45a0-8e27-c505c4ca1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(x=rand2, y = yrand2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740bb6c-ac0e-4208-9fe5-9abdc4dce526",
   "metadata": {},
   "source": [
    "### Example: Flexible Batch, Fixed Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ff784-218a-4fd9-93c5-a9fa65eedb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, timesteps, features))\n",
    "x = tf.keras.layers.LSTM(4)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model2 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Fixed_Timesteps\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model2)}\")\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532582f-3baf-4c68-89a3-9c17f32b947a",
   "metadata": {},
   "source": [
    "### Example 3: Flexible Batch Size, Flexible Timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23cd927-1945-43cb-8ba1-02707071e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducibility.set_seed(123)\n",
    "\n",
    "inputs = tf.keras.Input(batch_shape=(None, None, features))\n",
    "x = tf.keras.layers.LSTM(4)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model3 = tf.keras.Model(inputs, outputs, name = \"Flexible_Batch-Flexible_Timesteps\")\n",
    "print(f\"Initial Weights Hash: {hash_weights(model3)}\")\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7c03e-45a9-41fa-9fb9-e427feacc63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a947b-bff6-4041-9949-f2899f045f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0aa10-080f-4805-8b4b-0f77b68fd157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a6fc2-db2a-4ffe-8a09-14f2f2eaeb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ed5a2-aef8-4196-825d-f089509aacf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77e41e-6e90-49f5-8bb1-063f1b29da04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e204b8ce-c696-4f97-a4cb-21da029096cd",
   "metadata": {},
   "source": [
    "## Return Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca5f0c6-6db4-44e6-a179-5ebcb5799506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72acd8-a33e-4a6d-9972-4f96ffabbbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591edd8-4b81-4c63-9e6b-aa4708ab0012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7d601-cb99-45f5-8310-a61d4bce6d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f8d7b-f489-44c6-a561-7d2baac572c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944ff62-20b5-42c2-aeda-22f669196113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
