{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f4cc18-d23f-48ea-84dc-b0328a65e8e5",
   "metadata": {},
   "source": [
    "# Data Ingest of HRRR weather model data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321b093-c571-4527-a8c9-9c3f693fa489",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b506874e-a533-45c8-aa7e-f0208e6769ef",
   "metadata": {},
   "source": [
    "Weather data predictors for the ML models of FMC are retrieved from the HRRR weather model in this project. The 3D pressure model product from HRRR is utilized, since it has a larger set of variables than other products and it is used internally in other areas of the `wrfxpy` project. Additionally, since we require rainfall for modeling, we utilize the 3-hour forecast from HRRR and use the difference in accumulated precipitation from the 2 to 3 hour forecasts.\n",
    "\n",
    "There are 2 main uses for the HRRR weather data:\n",
    "\n",
    "1. For constructing training data sets\n",
    "2. For forecasting with a trained model over a spatial domain\n",
    "\n",
    "This notebook will demonstrate reading and calculating a set of predictors derived from the HRRR model for a spatial bounding box.\n",
    "\n",
    "### Metadata File\n",
    "\n",
    "The metadata file `../etc/variable_metadata/hrrr_metadata.yaml` has information about how to construct various predictors of FMC from HRRR grib file data. There are 4 types of features used in this project: HRRR modeled variables (e.g. wind speed), HRRR dimension variables (e.g. time), features engineered from HRRR modeled data (e.g. equilibrium moisture), and features engineered from HRRR dimension variables (e.g. hour of day). These 4 types of features must be extracted and constructed differently. Top level keys in the metadata file are fmda names used within this project:\n",
    "\n",
    "- HRRR data variables will specify HRRR naming convention, regex search string, and layer/level. Common layers are grouped together in data retrieval\n",
    "- HRRR dimension variables will specify a HRRR naming convention, but they can be read from any other set of HRRR data\n",
    "- Engineered features from HRRR data variables will specify the names of variables needed to calculate them. The names will exist as other top-level keys in this file\n",
    "- Engineered features from HRRR dimension variables will specify the names of the dimensions needed to calculate them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15892801-55fb-43a5-a416-cb15bb3f25da",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721c0f9-709d-4bfe-91f1-914c5a034af1",
   "metadata": {},
   "source": [
    "A configuration file is used to control data ingest. For automated processes, the code will look for a json configuration file depending on the use case: \n",
    "\n",
    "* For building training data, `../etc/training_data_config.json`\n",
    "* For deploying the model on a grid, `../etc/forecast_config.json`\n",
    "\n",
    "Retrieval of atmospheric weather predictors is done with the python software package `Herbie`. A module `retrieve_hrrr_api.py` has functions and other metadata for directing data ingest. A list of predictors will be provided in order to control the data downloading. Some of these predictors are derived features, such as equilibrium moisture content which is calculated from relative humidity and air temperature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8519a528-b973-46a7-a532-3e15864dd704",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "For more info on HRRR data bands and definitions, see [HRRR inventory](https://www.nco.ncep.noaa.gov/pmb/products/hrrr/hrrr.t00z.wrfprsf02.grib2.shtml) for pressure model f02-f38 forecast hours.\n",
    "\n",
    "For more info on python package, see Brian Blaylock's `Herbie` [python package](https://github.com/blaylockbk/Herbie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed774d-7bef-48e7-b9a6-8f4ba4e17d81",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "User definitions, these will come from config files in other areas of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b32fd-9d6b-4582-b724-4d2a094a6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from herbie import FastHerbie, paint, wgrib2, Herbie\n",
    "# from herbie.toolbox import EasyMap, ccrs, pc\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(\"../src\")\n",
    "from utils import Dict, read_yml, str2time, print_dict_summary, read_pkl\n",
    "import ingest.retrieve_hrrr_api as ih\n",
    "from viz import map_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfdc1d-f498-4404-9a00-c7c9f30931fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../etc/training_data_config.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)   \n",
    "    config = Dict(config)\n",
    "\n",
    "bbox = config.bbox\n",
    "start = str2time(config.start_time)\n",
    "end = str2time(config.end_time)\n",
    "features_list = config.features_list\n",
    "\n",
    "print(f\"Start Date of retrieval: {start}\")\n",
    "print(f\"End Date of retrieval: {end}\")\n",
    "print(f\"Spatial Domain: {bbox}\")\n",
    "print(f\"Required Features: {features_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23456364-3f67-4aee-941a-8ed7e23fad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_all = [*ih.hrrr_meta.keys()]\n",
    "# features_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6991cec8-bc96-42b9-868d-584f56abcb43",
   "metadata": {},
   "source": [
    "### Retrieve Data\n",
    "\n",
    "This function from `herbie` sets up a connection to read, but only what is requested later will be downloaded. Available data can be viewed with the `inventory()` method. *Note:* this will display a separate row for each time step requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623951c-9a77-45dc-870d-76b9e2ab2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of dates\n",
    "dates = pd.date_range(\n",
    "    start = start.replace(tzinfo=None),\n",
    "    end = end.replace(tzinfo=None),\n",
    "    freq=\"1h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ad005-cbf4-4e90-b857-072288fea936",
   "metadata": {},
   "outputs": [],
   "source": [
    "FH = FastHerbie(\n",
    "    dates, \n",
    "    model=\"hrrr\", \n",
    "    product=\"prs\",\n",
    "    fxx=range(3, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bdab6-4968-4b93-acab-bc9aab133b6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inv = FH.inventory()\n",
    "inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829738f2-83ff-4da0-9e44-990047d3d366",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Spatial Subset\n",
    "\n",
    "NOTE: as of Dec 31 2024, there are package issues with this solution. Herbie environment doesn't work either. TODO\n",
    "\n",
    "Brian Blaylock recommends downloaded the data and spatially subsetting using Herbie's wrapper for `wgrib2`, then recreating the objects and reading into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fbd4e4-a124-4fa0-8c00-f385e774be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5d968-9012-4ea5-96a5-21ba3f3b664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_fh_layer(FH, search_string, remove_grib=True, bbox=None, subset_naming=\"myRegion\"):\n",
    "#     \"\"\"\n",
    "#     Get HRRR data from fastherbie object given regex search string. \n",
    "#     Search string groups variables by layer/level. \n",
    "#     Optional bounding box spatially subsets data\n",
    "\n",
    "#     Arguments:\n",
    "#         - FH: FastHerbie object, defined with start and stop times\n",
    "#         - remove_grib: bool, whether or not to delete grib files returning to local read\n",
    "#         - search_string: str, based on regex. see utility function features_to_searchstr\n",
    "#         - bbox: list, optional bounding box to subset region\n",
    "\n",
    "#     Notes: As of Dec 18, 2024, Brian Blaylock recommends downloading data and using \n",
    "#         wgrib2 to spatially subset the data\n",
    "        \n",
    "#     Returns:\n",
    "#         xarray, optionally subsetted to a bounding box\n",
    "#     \"\"\"\n",
    "\n",
    "#     if bbox is None:\n",
    "#         print(\"Returning data for entire conus, deleting all downloaded gribs\")\n",
    "#         ds = FH.xarray(search_string, remove_grib=remove_grib)\n",
    "#     else:\n",
    "#         print(f\"Subsetting data to region within bbox: {bbox}\")\n",
    "#         print(f\"Downloading Data to run wgrib2\")\n",
    "\n",
    "#         files = FH.download(search_string)\n",
    "#         files = sorted(files, key=lambda x: int(x.name.split('__hrrr.t')[1][:2])) # sort by hour\n",
    "        \n",
    "#         # Reorder bbox to match format (min_lon, max_lon, min_lat, max_lat)\n",
    "#         extent = (bbox[1], bbox[3], bbox[0], bbox[2]) \n",
    "#         subset_files=[]\n",
    "#         for file in files:\n",
    "#             subset_files.append(wgrib2.region(file, extent, name=subset_naming))\n",
    "\n",
    "#         # Convert PosixPath list to strings\n",
    "#         file_list = [str(path) for path in subset_files]\n",
    "        \n",
    "#         # Open files as a combined dataset\n",
    "#         ds = xr.open_mfdataset(\n",
    "#             file_list,\n",
    "#             engine=\"cfgrib\",\n",
    "#             concat_dim=\"time\",  # Replace 'time' with the appropriate dimension\n",
    "#             combine=\"nested\" \n",
    "#         )        \n",
    "#         ds = ds.sortby('time')  \n",
    "\n",
    "#         # Delete Files\n",
    "#         if remove_grib:\n",
    "#             for file in files:\n",
    "#                 if file.exists():  # Check if the file exists before attempting to delete it\n",
    "#                     file.unlink()        \n",
    "#             for file in subset_files:\n",
    "#                 if file.exists():  # Check if the file exists before attempting to delete it\n",
    "#                     file.unlink()    \n",
    "                \n",
    "#     return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301fea9-7b5a-42d5-ac33-288a5151a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = search_strings['2m']\n",
    "\n",
    "# ds1 = get_fh_layer(FH, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b012ea-0db5-4739-8900-bce37f59e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds2 = get_fh_layer(FH, ss, remove_grib=False, bbox = bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249b518-5523-4cc1-97a3-02ae37a800df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get CRS from geographic herbie \n",
    "# ## Assuming this info doesn't change over time\n",
    "# H = Herbie(\"2023-08-01\", product=\"sfc\")\n",
    "# ds_hgt = H.xarray(\"(?:HGT|LAND):surface\")\n",
    "# crs = ds_hgt.herbie.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a0655-ebf2-4e9a-924f-d4745ac23ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from herbie.toolbox import EasyMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fbb0d8-34e1-40ef-9108-71f235af581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = EasyMap(crs=crs).STATES(color=\"k\").ax\n",
    "# ax.pcolormesh(ds_hgt.longitude, ds_hgt.latitude, ds_hgt.orog, cmap=paint.LandGreen.cmap, alpha=0.5, transform=pc)\n",
    "# ax.pcolormesh(ds2.longitude, ds2.latitude, ds2.t2m.isel(time=0), transform=pc)\n",
    "\n",
    "# ax.gridlines(xlocs=extent[:2], ylocs=extent[2:], color=\"k\", ls=\"--\", draw_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2353b-e888-4919-8ce9-abdbc0c5309d",
   "metadata": {},
   "source": [
    "Data fields are accessed through the `.xarray()` method. This will temporarily download the file and then deliver it in memory as an xarray object. Different variables are accessed through search strings that specify the variable name (e.g. air temperature), the level of the observation (e.g. surface level), and the forecast hour relative to the f00 start time (e.g. hour 3 as we will be using). The `retrieve_hrrr_api` module in this project stores a dataframe with names and info on various variables that will be considered for modeling FMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f13b63-b8d8-482b-bf53-514b43b090a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show HRRR naming dataframe\n",
    "# ih.hrrr_name_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9983a64-f0b8-4527-b4c3-d3624eb256f6",
   "metadata": {},
   "source": [
    "## Read Data from Multiple Layers\n",
    "\n",
    "We will demonstrate retrieval of a restricted set of predictors. Grib data is grouped by layer, or \"hypercube\". There are various options for combining data from different levels. See [Brian's solution](https://herbie.readthedocs.io/en/2024.3.1/user_guide/_bonus_notebooks/multiple_variables_and_merge.html) in the Herbie docs. In this project, we implement our own version.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "- From a list of features with fmda names, or standard names used in this project, get a list of regex search strings for accessing HRRR grib files. These strings will be grouped by layer for easy reading with `FastHerbie`\n",
    "- Read each separate layer of data and group, adding a dimension for height above ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4c127-41b8-48ef-9008-600e260eb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ingest.retrieve_hrrr_api\n",
    "importlib.reload(ingest.retrieve_hrrr_api)\n",
    "import ingest.retrieve_hrrr_api as ih\n",
    "\n",
    "print(f\"Target Features List: {features_list}\")\n",
    "search_strings = ih.features_to_searchstr(features_list)\n",
    "print(\"HRRR Search Strings:\")\n",
    "print_dict_summary(search_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fab779-5511-4a49-99f1-5b91b42170cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = {}\n",
    "\n",
    "for layer in search_strings:\n",
    "    print(f\"Reading HRRR data for layer: {layer}\")\n",
    "    print(f\"    search strings: {search_strings[layer]}\")\n",
    "    ds_dict[layer] = FH.xarray(search_strings[layer], remove_grib=False) # Keep grib for easier re-use, delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16b1e2-2ffb-49d4-9058-9e41b867d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d958371-001d-4ef8-b7e6-38acf197a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict[\"surface\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e8f6c-4d13-4fee-94e1-390aef36d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict[\"2m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67adb1b-bf02-426c-b4a8-e6ab2fabb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict[\"10m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f9854-bbc6-4db3-a6f0-b6f7d6b420ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ih.merge_datasets(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f8055-96cc-4046-b994-360cfc7042bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign_coords({\n",
    "    'grid_x' : ds.x,\n",
    "    'grid_y' : ds.y\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766a631-5d11-418f-ba12-d3e04678b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e984b-702b-4c55-b8e1-c17cf4642652",
   "metadata": {},
   "source": [
    "## Construct Predictors\n",
    "\n",
    "### Equilibrium Moisture Content\n",
    "\n",
    "Equilibrium moisture content is calculated from RH and air temp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e5e80-8c80-4628-bd3e-455d0e29e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingest.retrieve_hrrr_api import calc_eq\n",
    "calc_eq(ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a7da3-7ae0-4a18-af67-7966534c1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_var(ds, \"Ed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a78470-3899-4020-a6ca-647080064c7a",
   "metadata": {},
   "source": [
    "### Time-derived Predictors\n",
    "\n",
    "Hour of day (0-23) and day of year (1-366) added as coordinates to the spatial objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8f5de-2aad-4c01-a4a2-22c48ed7da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ih.calc_times(ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800db5a7-e8b4-4a21-a271-bd5e962647bb",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Maps are made with a wrapper function to the `EasyMap` functionality in the `Herbie` package. The function accesses metadat that should make it robust to renaming. The metadata stores color schemes from the NWS for certain variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd0e2d-6aff-4594-822e-3da8b4531ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you rename data this should still work\n",
    "# ds = ih.rename_ds(ds.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b83bfb6-45bf-4bd9-9282-d6c508e4dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_var(ds, \"wind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b963f6-4a94-4937-9101-4ce865b399cb",
   "metadata": {},
   "source": [
    "## Extracting and Formatting Training Set Data\n",
    "\n",
    "Training of models is done at the physical locations of RAWS stations, since that is where the observed FMC data are. To build training data for machine learning models, we use the `pick_points` accessor from Herbie at nearest neighbors to the lon/lat coordinates of the RAWS sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e84b76-2772-4230-81f5-b0821286eb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not osp.exists(\"../data/raws.pkl\"):\n",
    "    print(f\"No RAWS data found in {'../data/raws.pkl'}\")\n",
    "else:\n",
    "    raws = read_pkl(\"../data/raws2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f71c7c-605d-4afb-a280-0d64afc707fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9974bc4-3574-4795-9d4d-32fd77f5a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = []\n",
    "latitude = []\n",
    "stid = []\n",
    "for key in raws:\n",
    "    longitude.append(raws[key][\"loc\"][\"lon\"])\n",
    "    latitude.append(raws[key][\"loc\"][\"lat\"])\n",
    "    stid.append(raws[key][\"loc\"][\"stid\"])\n",
    "pts = pd.DataFrame({\n",
    "    \"longitude\" : longitude,\n",
    "    \"latitude\" : latitude,\n",
    "    \"stid\": stid\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50567e6e-a9c2-412c-8897-8ad5c1cacc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds2 = ih.rename_ds(ds.copy())\n",
    "ds_pts = ds.herbie.pick_points(pts, method = \"nearest\", k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc882c-1181-4875-af51-01d6a18e6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338e923-be01-4a7b-a514-bca3315cef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530bf11-1e5d-47cb-b9a5-7c08944aaa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pts.where(ds_pts.point_stid == \"HSYN1\", drop=True).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f63325-3ca8-4215-bc93-ea24d3ca59ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324d9d4-4fc4-408e-8526-553307c5cb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3055ed-f257-4f40-a4de-c8738846b5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba296aed-2a76-41d5-b27c-23b9fa8bae6a",
   "metadata": {},
   "source": [
    "## Formatting Forecast Data\n",
    "\n",
    "Forecasting with a trained model is done pointwise (for now) on the HRRR grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee0230-e335-45df-a9aa-9510b214178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_var(ds, \"Ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69020b5-46d7-41b8-b9b0-1cd0eabe7bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = [37, -111, 46, -95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e8e53-8ef3-479e-ae26-62ceaa9f7c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = pd.DataFrame({\n",
    "    \"latitude\": [bbox[0], bbox[2], bbox[0], bbox[2]],\n",
    "    \"longitude\": [bbox[1], bbox[3], bbox[1], bbox[3]]\n",
    "})\n",
    "\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddc80d-1977-411a-ba50-d3b4aea8b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_bbox = ds.herbie.pick_points(pts)\n",
    "ds_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1ad53-ffad-43bb-a962-005a28a93068",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax = int(ds_bbox.grid_x.min()), int(ds_bbox.grid_x.max())\n",
    "ymin, ymax = int(ds_bbox.grid_y.min()), int(ds_bbox.grid_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39633fb1-a3eb-4bed-90e4-1463526f25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b048dea-039e-48f7-9e22-de9bef9cda1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da4793-0d91-450d-8ed6-fde4887c539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cropped = ds.sel(x=slice(xmin, xmax), y=slice(ymin, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d857fc-971b-42e9-95b7-928de198df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_var(ds_cropped, \"Ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccaca1-588a-4120-8e4d-1b23177b6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from herbie import paint\n",
    "from herbie.toolbox import EasyMap, pc, ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6bcbd-a837-413b-93aa-e56e2a086f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = EasyMap(\"110m\", figsize=[15, 9], crs=ds.herbie.crs).STATES().ax\n",
    "p = ax.pcolormesh(\n",
    "    ds.longitude,\n",
    "    ds.latitude,\n",
    "    ds.Ed.isel(time=0),\n",
    "    transform=pc,\n",
    "    cmap=paint.NWSRelativeHumidity.cmap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5189dfc-6a8c-4da8-a8a3-c5f22a4a5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = EasyMap().STATES().OCEAN().LAND().DOMAIN(ds_cropped).ax\n",
    "ds[\"test\"] = ds.Ed.where(ds.Ed < -100)\n",
    "ax = EasyMap(\"110m\", figsize=[15, 9], crs=ds.herbie.crs).STATES().ax\n",
    "p = ax.pcolormesh(\n",
    "    ds.longitude,\n",
    "    ds.latitude,\n",
    "    ds.test.isel(time=0),\n",
    "    transform=pc,\n",
    "    cmap=paint.NWSRelativeHumidity.cmap,\n",
    ")\n",
    "p = ax.pcolormesh(\n",
    "    ds_cropped.longitude,\n",
    "    ds_cropped.latitude,\n",
    "    ds_cropped.Ed.isel(time=0),\n",
    "    transform=pc,\n",
    "    cmap=paint.NWSRelativeHumidity.cmap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8d406-cd91-41ef-8ed5-99d49c00f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cropped2 = ds.copy()\n",
    "ds_cropped2[\"test2\"] = ds.Ed.where(((ds.latitude > ds_bbox.latitude.min()) & (ds.latitude < ds_bbox.latitude.max()) & (ds.longitude > ds_bbox.longitude.min()) & (ds.longitude < ds_bbox.longitude.max())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa3e10-b8e9-46ea-989a-02058e727aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"test\"] = ds.Ed.where(ds.Ed < -100)\n",
    "ax = EasyMap(\"110m\", figsize=[15, 9], crs=ds.herbie.crs).STATES().ax\n",
    "p = ax.pcolormesh(\n",
    "    ds.longitude,\n",
    "    ds.latitude,\n",
    "    ds.test.isel(time=0),\n",
    "    transform=pc,\n",
    "    cmap=paint.NWSRelativeHumidity.cmap,\n",
    ")\n",
    "p = ax.pcolormesh(\n",
    "    ds_cropped2.longitude,\n",
    "    ds_cropped2.latitude,\n",
    "    ds_cropped2.test2.isel(time=0),\n",
    "    transform=pc,\n",
    "    cmap=paint.NWSRelativeHumidity.cmap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9680f-840f-4a21-8c8b-5d32a50fc158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848477f-cb31-4e6b-8a9b-7e50632f7e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255ae6b-0f94-43fd-9a76-1903f32755d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0af6ff5-d8fe-4349-9cbf-c1e929343e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4c88f6-fc61-4e32-a6e4-7b5cbbb619b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be290e4b-684c-48d8-931d-7716471ff7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6901c78a-8f6f-4af7-8fbe-e0e15dea0b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
